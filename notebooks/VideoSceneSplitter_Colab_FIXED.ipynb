{"cells": [{"cell_type": "code", "metadata": {}, "source": ["# \ud83d\udcc1 Importar librer\u00edas necesarias\n", "import os\n", "import torch\n", "import ffmpeg\n", "import numpy as np\n", "from transformers import VideoMAEFeatureExtractor, VideoMAEModel\n", "from decord import VideoReader, cpu"], "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": ["# \ud83d\udee0\ufe0f Funciones auxiliares\n", "def get_video_clips(video_path, clip_duration):\n", "    vr = VideoReader(video_path, ctx=cpu(0))\n", "    num_frames = len(vr)\n", "    fps = vr.get_avg_fps()\n", "    clip_len = int(fps * clip_duration)\n", "    clips = []\n", "    for start in range(0, num_frames, clip_len):\n", "        end = min(start + clip_len, num_frames)\n", "        clip = vr.get_batch(list(range(start, end)))\n", "        clips.append(clip)\n", "    return clips\n", "\n", "def extract_embeddings(clips, model, processor):\n", "    embeddings = []\n", "    for clip in clips:\n", "        inputs = processor(list(clip.asnumpy()), return_tensors=\"pt\")\n", "        with torch.no_grad():\n", "            outputs = model(**inputs)\n", "        embeddings.append(outputs.last_hidden_state.mean(dim=1).squeeze(0).numpy())\n", "    return np.array(embeddings)\n", "\n", "def detect_scene_changes(embeddings, threshold=0.75):\n", "    scene_changes = [0]\n", "    for i in range(1, len(embeddings)):\n", "        sim = np.dot(embeddings[i-1], embeddings[i]) / (\n", "            np.linalg.norm(embeddings[i-1]) * np.linalg.norm(embeddings[i])\n", "        )\n", "        if sim < threshold:\n", "            scene_changes.append(i)\n", "    return scene_changes\n", "\n", "def split_video(input_path, scene_changes, clip_duration, output_dir):\n", "    os.makedirs(output_dir, exist_ok=True)\n", "    for idx, scene_idx in enumerate(scene_changes):\n", "        start = scene_idx * clip_duration\n", "        output = os.path.join(output_dir, f\"scene_{idx+1}.mp4\")\n", "        ffmpeg.input(input_path, ss=start, t=clip_duration).output(output, codec='copy').run(overwrite_output=True)"], "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": ["# \ud83d\ude80 Ejecutar flujo completo\n", "clip_duration = 1.0\n", "threshold = 0.75\n", "video_path = \"video.mp4\"\n", "\n", "if not os.path.exists(video_path):\n", "    from google.colab import files\n", "    print(\"\u26a0\ufe0f Archivo no encontrado. Sube tu video ahora...\")\n", "    uploaded = files.upload()\n", "\n", "print(\"[INFO] Cargando modelo...\")\n", "processor = VideoMAEFeatureExtractor.from_pretrained(\"MCG-NJU/videomae-base\")\n", "model = VideoMAEModel.from_pretrained(\"MCG-NJU/videomae-base\")\n", "\n", "print(\"[INFO] Extrayendo clips...\")\n", "clips = get_video_clips(video_path, clip_duration)\n", "\n", "print(\"[INFO] Generando embeddings...\")\n", "embeddings = extract_embeddings(clips, model, processor)\n", "\n", "print(\"[INFO] Detectando cortes de escena...\")\n", "scene_changes = detect_scene_changes(embeddings, threshold)\n", "print(\"Cortes detectados:\", scene_changes)\n", "\n", "print(\"[INFO] Cortando video...\")\n", "split_video(video_path, scene_changes, clip_duration, \"escenas\")\n", "print(\"[LISTO] Escenas generadas en la carpeta 'escenas'\")"], "outputs": [], "execution_count": null}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.11"}}, "nbformat": 4, "nbformat_minor": 5}