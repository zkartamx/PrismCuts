{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62ce1029",
   "metadata": {},
   "source": [
    "# üé¨ Video Scene Splitter en Google Colab\n",
    "Este notebook te permite segmentar autom√°ticamente un video en escenas utilizando el modelo `VideoPrism` de Google."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7eb816e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîß Instala dependencias\n",
    "!pip install torch transformers ffmpeg-python scikit-learn opencv-python -q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a09857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üì• Sube tu video o c√°rgalo desde Drive\n",
    "from google.colab import files\n",
    "uploaded = files.upload()  # Subir el archivo .mp4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd66c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìö Importar librer√≠as\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoProcessor, AutoModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import ffmpeg\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fac447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚öôÔ∏è Funciones: extracci√≥n de clips y embeddings\n",
    "def get_video_clips(video_path, seconds_per_clip=1.0):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frames_per_clip = int(fps * seconds_per_clip)\n",
    "    clips, frames = [], []\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frames.append(frame_rgb)\n",
    "        if len(frames) == frames_per_clip:\n",
    "            clips.append(frames.copy())\n",
    "            frames.clear()\n",
    "    cap.release()\n",
    "    return clips\n",
    "\n",
    "def extract_embeddings(clips, model, processor):\n",
    "    embeddings = []\n",
    "    for clip in clips:\n",
    "        inputs = processor(videos=[clip], return_tensors=\"pt\")\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            emb = outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()\n",
    "            embeddings.append(emb)\n",
    "    return embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadd7e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìâ Detecci√≥n de cambios de escena\n",
    "def detect_scene_changes(embeddings, threshold=0.75):\n",
    "    scene_changes = [0]\n",
    "    for i in range(len(embeddings) - 1):\n",
    "        sim = cosine_similarity([embeddings[i]], [embeddings[i + 1]])[0][0]\n",
    "        if sim < threshold:\n",
    "            scene_changes.append(i + 1)\n",
    "    return scene_changes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff57e496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÇÔ∏è Cortar video con FFmpeg\n",
    "def split_video(input_path, scene_changes, seconds_per_clip, output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    for i in range(len(scene_changes) - 1):\n",
    "        start = scene_changes[i] * seconds_per_clip\n",
    "        duration = (scene_changes[i + 1] - scene_changes[i]) * seconds_per_clip\n",
    "        output_path = os.path.join(output_dir, f\"scene_{i + 1}.mp4\")\n",
    "        (\n",
    "            ffmpeg\n",
    "            .input(input_path, ss=start, t=duration)\n",
    "            .output(output_path, codec='copy')\n",
    "            .run(overwrite_output=True)\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173da309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üöÄ Ejecutar el flujo\n",
    "video_path = list(uploaded.keys())[0]  # Solo toma el primer archivo subido\n",
    "clip_duration = 1.0  # segundos por clip\n",
    "threshold = 0.75     # umbral de similitud\n",
    "\n",
    "print(\"[INFO] Cargando modelo...\")\n",
    "processor = AutoProcessor.from_pretrained(\"google/videoprism\")\n",
    "model = AutoModel.from_pretrained(\"google/videoprism\")\n",
    "\n",
    "print(\"[INFO] Extrayendo clips...\")\n",
    "clips = get_video_clips(video_path, clip_duration)\n",
    "\n",
    "print(\"[INFO] Generando embeddings...\")\n",
    "embeddings = extract_embeddings(clips, model, processor)\n",
    "\n",
    "print(\"[INFO] Detectando cortes de escena...\")\n",
    "scene_changes = detect_scene_changes(embeddings, threshold)\n",
    "print(\"Cortes detectados:\", scene_changes)\n",
    "\n",
    "print(\"[INFO] Cortando video...\")\n",
    "split_video(video_path, scene_changes, clip_duration, \"escenas\")\n",
    "\n",
    "print(\"[LISTO] Escenas generadas en la carpeta 'escenas'\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}